---
title: "Econometrics R Manual"
author: "Roman Sigalov"
date: "8 August 2016"
output:
  html_document:
    highlight: pygments
    toc: yes
---

### Introduction
R reminds much more of a traditional programming language when compared to STATA. Hence its capabilities are much bigger and econometrics is not the only subject where you can use it. It is widely used among researches including economists, in data science, machine learning and other fields. One of the best things about R is that it is FREE and OPEN-SOURCE which mean that if you prefer R to STATA you get (1) great variety of packages capable of doing almost anything and (2) enormous community (on such platforms as stackexchange) which is able to give you an answer on virtually every question. So, if decide to use R during this semester, you are more than welcome to ask help from me, but I strongly encourage you to google your question first, after all, this is the way that even experienced programmist work, they google.

However, there are drawbacks in using R. The most important (and some may say that the only one) is that its learning curve is very steep. It is hard to start programming in R, understand how the function work and how to deal with new problems. The second thing is that its function are limited out-of-the-box and you need to download additional packages if you want to have more functionality. 

In this tutorial, which I will be updating on a constant basis, I will explain how to do everything that Konstantin is doing in STATA as well as some specific things about this language and overview of an incredibly powerful plotting package called "ggplot2".

### Basics
Here we will cover the main features of R that are not related to econometrics. We will cover basic data types, how to do basic operations and some trickier stuff that you will need in the future.

#### Scalars and Vectors
Let's start from the very beginning. You can assign value to variables using `<-`, `->` or `=`:
```{r}
a <- 3
4 -> b # try not to do it at all
c = 5
a
b
c
```
R is designed to work with vectors and operatins in vector/ matrix forms are done very quickly. So try to use them instead of loop whenever possible. Creating vector and doing some operations on it:
```{r}
x <- c(1,2,3,4,5)
x[3] # first element has index 1, not 0
mean(x) # mean of vector values
sd(x) # standard deviation of vector values
median(x) # median value of vector values
```
By default when you are doing some operations on vector it is done element by element:
```{r}
y <- c(6,7,8,9,10)
x + y
x * y
5 * y
```
If you want to multiply vectors in matrix form you need to specify it using `%*%`. For transposition use function `t()`:
```{r}
x %*% y
x %*% t(y)
```

#### Matrices
In order to create a matrix use command `matrix()` specifying vector and number of columns/rows:
```{r}
mat <- matrix(c(1,2,7,4,5,10,7,11,9), nrow = 3)
mat1 <- matrix(c(1,2,3,4,5,6), ncol = 2)
mat
mat1
```
Pay attention to the fact that values are filled row-by-row to the matrix. Operations in scalar form work element-by-element as it was with vectors. Of course, we can multiply matrices, just pay attention to their dimesions or you will get an error:
```{r}
mat %*% mat1
t(mat1) %*% mat
```
You can calculate determinant using `det()`:
```{r}
det(mat)
```

### Data.
Here I will explain how to get data into R. Both from local computer in different formats as well as from the web.

### Loops, conditional statements and other.

### Packages
Here I will highlight several packages that are very useful for data analysis and for your econometrics class as well. Some of them may do things that will be required later in the semester. So, if you do not understand yet what is Newey-West errors don't bother, you will catch up later.

Almost every package that you will need are stored in so called The Comprehensive R Archive Network (CRAN). It means that you can simply install them by typing
```{r,eval=FALSE}
install.packages("ggplot2")
```
in R-console or RStudio. Lets list the packages that are either important for the course or give some interesting new function.

```{r,eval=FALSE}
library("sandwich")
```
is able to compute various kinds of standard errors including, White (Heteroskedasticity consistent errors, hence HC) and Newey-West (Heteroskedasticity and Autocorrelation Consistent errors, hence HAC).

```{r,eval=FALSE}
library("ggplot2")
library("ggthemes")
```
first is able to plot almost anything you will every need to plot. Second adds additional themes to ggplot: you can make you graph look like The Economist Graph, WSJ or even STATA graph.

```{r,eval=FALSE}
library("sqldf")
```
allows you to manipulate data using SQLite language. If you you know SQL well it will probably become your favorite package. Otherwise, I will either show you how to do some stuff in it, or you may not bother much

```{r,eval=FALSE}
library("reshape")
```
allows you to do reverse pivot and other interesting things. **show reverse pivot example**

```{r,eval=FALSE}
library("DataCombine")
```
allows you to easily create lags for you regression

```{r,eval=FALSE}
library("xts")
```
additional capabilities for time series data manipulation, will be covered later. Below you can find other interesting packages.

```{r}
library("stargazer")
```
allows you to export regression results into LaTeX format.

```{r,eval=FALSE}
library("TTR") # for rolling volatility
library("lubridate") # for operations on dates
library("ghyp")
library("MASS")
library("xts")
library("memisc")
library("grid") # for arranging plots in grid
library("psych")
library("FinTS") # For GARCH regressions
library("fGarch")
```

### Regressions I. Basics
Here we are going to do a simple regression on our demo dataset. I will show how to access coefficients, predict, convert output to LaTeX and plot results.

We are going to use data from CRSP and study companys' cash balances and what affects them. Let's import data and look what columns do we need:
```{r}
setwd("~")
data <- read.csv("/Users/rsigalov/Documents/HSENES/7Semester/R\ Econometrics\ Handbook/CRSP_data.csv", sep = ";")
colnames(data)
```
Let's first estimate regression:
$$ cash_i = \beta_0 + \beta_1ind\_cf\_vol_i + \varepsilon_i $$
since volatility of cash flow of the industry ($ind\_cf\_vol$) may be positively related to the cash that the firm wants to hold to absorb risks. Use command summary to print the output of the regression:
```{r}
model <- lm(data = data, cash ~ ind_cf_vol)
summary(model)
```
The object that `summary()` command creates contains a lot of useful information. For example:
```{r}
sum <- summary(model)
sum$coefficients # outputs a matrix
sum$r.squared
sum$fstatistic
```
Using coefficients we can manually predict cash balance:
```{r}
beta_0 <- sum$coefficients[1,1]
beta_1 <- sum$coefficients[2,1]
ind_cf_vol_1 <- 0.05
beta_0 + beta_1 * ind_cf_vol_1
```
But, of course, we can predict easier using our model object:
```{r}
predict(model, newdata = (ind_cf_vol = 0.05))
```
or we can do it for several points (but we need to insert dataframe)
```{r}
predict(model, newdata = data.frame(ind_cf_vol = c(0.05, 0.06, 0.07, 0.08)))
```
and add confidence interval
```{r}
predict(model, newdata = data.frame(ind_cf_vol = c(0.05, 0.06, 0.07, 0.08)), interval = "confidence")
```
Let's plot our results using ggplot (in more details it will be explained in the next part):
```{r, warning=FALSE,fig.align='center'}
library("ggplot2")
ggplot(data = data, aes(x = ind_cf_vol, y = cash)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) # fitting a line
```
Fitting multivariate regression and prediction is just as simple:
```{r}
model2 <- lm(data = data, cash ~ ind_cf_vol + rd_to_sales)
predict(model2, 
        newdata = data.frame(ind_cf_vol = c(0.05, 0.06), 
                             rd_to_sales = c(0.3, 0.45)),
        interval = "confidence")
```
Next we are going to export summary for the second to LaTeX format using package `stargazer`:
```{r}
library("stargazer")
stargazer(model2, type = "latex", df=FALSE, dep.var.labels = NULL, report = "vcp")
```
Now you can copy and paste this code into latex and you will get a nice table. You can include different model into the same output latex-code and specify errors (standard errors will be covered in a great details later) that you want to report:
```{r, results=FALSE}
library("sandwich")
se_model <- sqrt(diag(vcovHC(model)))
se_model2 <- sqrt(diag(vcovHC(model2)))

knitr::kable(stargazer(model, model2, type = "html", report = "vcp",
          se = list(se_model, se_model2)))
```
Here I used `knitr::kable()` to directly put a table into html file. Stargazer has a lot of capabilities, for reference use this link http://jakeruss.com/cheatsheets/stargazer.html

### Plotting. Introduction to ggplot2.
`ggplot2` is a wonderful package which will help you to create beautiful graphs. It can be tricky at first but as your demands will grow it will become indisensible. First let's create simple graph without ggplot, because it is easier to do it this way.
```{r}
time <- seq(0,10,0.01)
ts <- sapply(time, sin)
plot(x = time, y = ts, type = "l")
```
`sapply` is a very powerful function, it takes vector (in our case `time`) and applies function `sin` elementwise. If you will create your own function you can use it as well. For example:
```{r}
time <- seq(0,10,0.01)
func <- function(x) {sin(x) + x}
ts <- sapply(time, func)
plot(x = time, y = ts, type = "l")
```
`ggplot` is definitely worse in plotting such data. Hence, I will show how to use it for more complicated datasets with a lot of variables that we want to somehow represent. 

I have two datasets which represent results of backtesting of a trading strategy. First file contains parameters on the beginning of the backtest, second file on the end.
```{r, message=FALSE}
setwd("~")
first <- read.csv("/Users/rsigalov/Documents/HSENES/7Semester/R\ Econometrics\ Handbook/EURUSD_first.csv", sep = ";")
last <- read.csv("/Users/rsigalov/Documents/HSENES/7Semester/R\ Econometrics\ Handbook/EURUSD_last.csv", sep = ";")
colnames(first)
```
I will do some manipulations with these files and show which columns do we have in the end:
```{r, message=FALSE}
stats <- merge(x = first, y = last, by = c("Scenario", "Scenario_Group"))
stats$scenario_group <- stats$Scenario_Group
stats$scenario <- stats$Scenario
stats$spot_chg <- stats$Spot.y - stats$Spot.x
stats$position_value_chg <- stats$Position_Value.y + stats$Acc_Trading_Gain.y - stats$Option_Value.x
stats$trades <- stats$Trades
stats$option_chg <- stats$Option_Value.y - stats$Option_Value.x

stats <- stats[names(stats) %in% c("scenario_group", "scenario", "spot_chg", "position_value_chg", "trades", "option_chg")]

colnames(stats)
```
We have different scenario groups and different scenarios. First, let's plot change in position value against change in spot price of asset:

```{r}
library("ggplot2")
ggplot(stats[stats$scenario_group == 160,], aes(x = spot_chg, y = position_value_chg)) +
  geom_point()
```

However, we might want to show different groups we can do it by adding color into aes with which will depend on group:

```{r}
ggplot(stats, aes(x = spot_chg, y = position_value_chg, color = scenario_group)) +
  geom_point()
```

ggplot suggested to use continuous scale for our groups, however, they are discrete and we can specify it by adding `factor()` around `scenario_group`:

```{r}
ggplot(stats, aes(x = spot_chg, y = position_value_chg, color = factor(scenario_group))) +
  geom_point()
```

It looks like a mess, maybe it is better give each group a separate point type:

```{r}
ggplot(stats, aes(x = spot_chg, y = position_value_chg, shape = factor(scenario_group))) +
  geom_point()
```

Well, there are not such as many point types. We can separate each group into seprate graph:
```{r}
stats$scenario_group <- as.character(stats$scenario_group)
ggplot(stats, aes(x = spot_chg, y = position_value_chg)) +
  geom_point() +
  facet_wrap(~scenario_group)
```

Above I converted scenario_group column in character format from numerical, to avoid using `factor()`, for some reasons it doesn't work in facet. Of course, we can do not only points, but also lines. Below, I will show several examples. I have the following data:
```{r}
price_data <- read.csv("/Users/rsigalov/Documents/HSENES/7Semester/R\ Econometrics\ Handbook/price_dynamics.csv", sep = ",")
colnames(price_data)
unique(price_data$sigma_e)
unique(price_data$k_d)
unique(price_data$lambda)
```
Let's first pick some values for `sigma_e`, `k_d` and `lambda`. I want to plot `price` against `time` and want to distinguish whether `price_cond` was above or below zero. 
```{r}
price_data_sub <- price_data[price_data$sigma_e==1 & price_data$k_d==1 & price_data$lambda==1,]
ggplot(price_data_sub, aes(x = time, y = price, color = factor(price_cond >= 0))) +
  geom_line()
```
Now I want to add different lines types for values of `lambda` (here we need to use `factor()` again):
```{r}
price_data_sub <- price_data[price_data$sigma_e==1 & price_data$k_d==1,]
ggplot(price_data_sub, aes(x = time, y = price, color = factor(price_cond >= 0), linetype = factor(lambda))) +
  geom_line()
```

and then we can make a grid with horizontal separation by `k_d` and vertical by `sigma_e`:
```{r, fig.height=10, fig.width=10}
ggplot(price_data, aes(x = time, y = price, color = factor(price_cond >= 0), linetype = factor(lambda))) +
  geom_line() +
  facet_grid(sigma_e ~ k_d)
```

Using combinations of facetting, linetype, linecolors you can show various proprties of a data on one single plot. This is just basics of `ggplot` I will include chapter on additional features later on. Meanwhile you can use this cheatsheet https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf which is really helpful.

### Regressions II. Standard Errors
Here I will show how to change standard errors as well as how to manipulate variance-covariance matrices and other important stuff. I will give you several examples of how to build confidence intervals and make graphs clearly representing your point.

Let's continue to work with our previous example and subset data to include only one year. Use `unique()` function to select only inique values from a vector:
```{r}
unique(data$year) # Determining which years there are
data2016 <- subset(x = data, year == 2016)
```
Since we might expect that each error are different for each firm we might want to use White standard errors. Using package `sandwich` we can estimate Heteroskedasticity consistent variance-covariance matrix:
```{r,message=FALSE}
library("sandwich")
model <- lm(data = data, cash ~ ind_cf_vol + rd_to_sales)
vcovHC(model) # Variance convariance matrix
diag(vcovHC(model)) # Diagonal elements of VCOV
sqrt(diag(vcovHC(model))) # standard errors
```
We can then test the coefficients using new errors using package `lmtest` and save these errors for subsequent use, for example, to export to LaTeX:
```{r,message=FALSE}
library("lmtest")
coeftest(model, vcov = vcovHC(model))
model_se <- sqrt(diag(vcovHC(model)))
```
Now we can create a LaTeX output with new standard errors **make Latex output table**.

Later you will need to use Heteroskedasticity and Autocorrelation consistent standard error (or Newey-West standard errors) which can be evaluated using the same way and function `vcovHAC()`.

### Regressions III. Transformatin of variables
Here I will show you how to transform your variables to perform log-linear, linear-log, log-log, power and other regressions. First, you can always add another variable to the dataset and oridary regression:
```{r,message=FALSE}
data$log_rd_to_sales <- log(data$rd_to_sales)
head(data$log_rd_to_sales)
```
There are a lot of zeros, thus we need to exclude such observations in order to perform log regression:
```{r,message=FALSE}
data_tmp <- data[data$rd_to_sales != 0, ]
data_tmp$log_rd_to_sales <- log(data_tmp$rd_to_sales)
model <- lm(data = data_tmp, formula = cash ~ ind_cf_vol + log_rd_to_sales)
```
or you can simply specify it in the `lm()` function to create different kind of regressions:
```{r,message=FALSE}
model <- lm(data = data_tmp, formula = cash ~ ind_cf_vol + log(rd_to_sales)) # linear-log
model <- lm(data = data_tmp, formula = log(cash) ~ ind_cf_vol + rd_to_sales) # log-linear
model <- lm(data = data_tmp, formula = log(cash) ~ ind_cf_vol + log(rd_to_sales)) # log-log
```
In order to perform, for example, quadratic regression, we may again create additional variable:
```{r,message=FALSE}
data$ind_cf_vol_sqr <- (data$ind_cf_vol)^2
model <- lm(data = data, formula = cash ~ ind_cf_vol + ind_cf_vol_sqr)
```
or make the transformation inside `lm()` function using `I()`. You can add different transformation of the same variable (for example for fitting $y = \beta_0 + \beta_1 x + \beta_2 x^2$ using `I()` as well:
```{r,message=FALSE}
model <- lm(data = data, formula = cash ~ ind_cf_vol + I(ind_cf_vol^2))
model <- lm(data = data, formula = cash ~ ind_cf_vol + I(ind_cf_vol^2) + I(ind_cf_vol^3))
```

### Tables
Here I will show you how to create LaTeX tables for your descriptive statistics and other

### Regressions IV. F-statistics
In this section I will show you how to compute F-statistics for the regression and in general how to test linear hypotheses. This can be done using package `car`. Let's get back to our example with CRSP data and issue of companys' cash holdings with several explanatory variables:
```{r}
setwd("~")
data <- read.csv("/Users/rsigalov/Documents/HSENES/7Semester/R\ Econometrics\ Handbook/CRSP_data.csv", sep = ";")
model <- lm(data = data, formula = cash ~ market_to_book + ind_cf_vol + rd_to_sales)
summary(model)
```
Well summary already provides you with F-statistics, however, using standard standard errors, and we might want to use HC errors. Import `car` library and test simple F-statistics:
```{r}
library("car")
# exactly what is shown in the summary of the regression above
linearHypothesis(model, c("market_to_book = 0", "ind_cf_vol = 0", "rd_to_sales = 0"))
# Some abstract hypothesis
linearHypothesis(model, c("2 * market_to_book - 5*ind_cf_vol = 0"))
```
If you want to include intercept into linear hypothesis use `(Intercept)` variable:
```{r}
linearHypothesis(model, c("2 * (Intercept) - 5*ind_cf_vol = 0"))
```
Of course, you may want to use non-standard standard errors. In order to do it you can supply variance-covariance matrix into hypothesis test. In the example below I supply heteroskedasticity-consistent standard errors:
```{r}
linearHypothesis(model, c("market_to_book = 0", "ind_cf_vol = 0", "rd_to_sales = 0"),
                 vcov = vcovHC(model))
```


### Regressions V. Probit and Logit
Have you heard of neural networks? If you did and want to understand how they are working you first need to get Probit and Logit.

### Plotting. More advanced ggplot2.

### Dates, dates, dates...
Working with dates is the most difficult part of data analysis, they are so unstandartised.

### Regressions VI. Panel data

### Regressions VII. Instrumental Variables and their friends

### Regressions VIII. Time Series

### Some Machine Learning for Prediction










